@misc{https://doi.org/10.48550/arxiv.1712.05877,
  doi = {10.48550/ARXIV.1712.05877},
  
  url = {https://arxiv.org/abs/1712.05877},
  
  author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{bjorck2018understanding,
      title={Understanding Batch Normalization}, 
      author={Johan Bjorck and Carla Gomes and Bart Selman and Kilian Q. Weinberger},
      year={2018},
      eprint={1806.02375},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gholami2021survey,
      title={A Survey of Quantization Methods for Efficient Neural Network Inference}, 
      author={Amir Gholami and Sehoon Kim and Zhen Dong and Zhewei Yao and Michael W. Mahoney and Kurt Keutzer},
      year={2021},
      eprint={2103.13630},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2022mqbench,
      title={MQBench: Towards Reproducible and Deployable Model Quantization Benchmark}, 
      author={Yuhang Li and Mingzhu Shen and Jian Ma and Yan Ren and Mingxin Zhao and Qi Zhang and Ruihao Gong and Fengwei Yu and Junjie Yan},
      year={2022},
      eprint={2111.03759},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{VALUEVA2020232,
title = {Application of the residue number system to reduce hardware costs of the convolutional neural network implementation},
journal = {Mathematics and Computers in Simulation},
volume = {177},
pages = {232-243},
year = {2020},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2020.04.031},
url = {https://www.sciencedirect.com/science/article/pii/S0378475420301580},
author = {M.V. Valueva and N.N. Nagornov and P.A. Lyakhov and G.V. Valuev and N.I. Chervyakov},
keywords = {Image processing, Convolutional neural networks, Residue number system, Quantization noise, Field-programmable gate array (FPGA).},
abstract = {Convolutional neural networks are a promising tool for solving the problem of pattern recognition. Most well-known convolutional neural networks implementations require a significant amount of memory to store weights in the process of learning and working. We propose a convolutional neural network architecture in which the neural network is divided into hardware and software parts to increase performance and reduce the cost of implementation resources. We also propose to use the residue number system (RNS) in the hardware part to implement the convolutional layer of the neural network. Software simulations using Matlab 2018b showed that convolutional neural network with a minimum number of layers can be quickly and successfully trained. The hardware implementation of the convolution layer shows that the use of RNS allows to reduce the hardware costs on 7.86%–37.78% compared to the two’s complement implementation. The use of the proposed heterogeneous implementation reduces the average time of image recognition by 41.17%.}
}

@Book{Skansi2018-as,
  title     = "Introduction to deep learning",
  author    = "Skansi, Sandro",
  publisher = "Springer International Publishing",
  series    = "Undergraduate Topics in Computer Science",
  edition   =  1,
  month     =  feb,
  year      =  2018,
  address   = "Cham, Switzerland",
  language  = "en"
}

@BOOK{Sze2020-ke,
  title     = "Efficient processing of deep neural networks",
  author    = "Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel
               S",
  publisher = "Springer International Publishing",
  series    = "Synthesis Lectures on Computer Architecture",
  month     =  jun,
  year      =  2020,
  address   = "Cham, Switzerland",
  language  = "en"
}

@inproceedings{Vaverka_2020,
	doi = {10.23919/date48585.2020.9116299},
  
	url = {https://doi.org/10.23919/date48585.2020.9116299
 },
  
	year = 2020,
	month = {mar},
  
	publisher = {{IEEE}
},
  
	author = {Filip Vaverka and Vojtech Mrazek and Zdenek Vasicek and Lukas Sekanina},
  
	title = {{TFApprox}: Towards a Fast Emulation of {DNN} Approximate Hardware Accelerators on {GPU}},
  
	booktitle = {2020 Design, Automation \& Test in Europe Conference \& Exhibition ({DATE})}
}

@misc{nagel2021white,
      title={A White Paper on Neural Network Quantization}, 
      author={Markus Nagel and Marios Fournarakis and Rana Ali Amjad and Yelysei Bondarenko and Mart van Baalen and Tijmen Blankevoort},
      year={2021},
      eprint={2106.08295},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{howard2017mobilenets,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{nagel2019datafree,
      title={Data-Free Quantization Through Weight Equalization and Bias Correction}, 
      author={Markus Nagel and Mart van Baalen and Tijmen Blankevoort and Max Welling},
      year={2019},
      eprint={1906.04721},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{krishnamoorthi2018quantizing,
      title={Quantizing deep convolutional networks for efficient inference: A whitepaper}, 
      author={Raghuraman Krishnamoorthi},
      year={2018},
      eprint={1806.08342},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{7738524,
  author={Chen, Yu-Hsin and Krishna, Tushar and Emer, Joel S. and Sze, Vivienne},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks}, 
  year={2017},
  volume={52},
  number={1},
  pages={127-138},
  doi={10.1109/JSSC.2016.2616357}}

@INPROCEEDINGS{9975395,
  author={Seshadri, Kiran and Akin, Berkin and Laudon, James and Narayanaswami, Ravi and Yazdanbakhsh, Amir},
  booktitle={2022 IEEE International Symposium on Workload Characterization (IISWC)}, 
  title={An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={79-91},
  doi={10.1109/IISWC55918.2022.00017}}

@ARTICLE{8686088,
  author={Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel and Sze, Vivienne},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices}, 
  year={2019},
  volume={9},
  number={2},
  pages={292-308},
  doi={10.1109/JETCAS.2019.2910232}}

@Website{edge-tpu-website,
author={Google},
title={Edge TPU},
url={https://cloud.google.com/edge-tpu}
}

@ARTICLE{726791,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@Website{post-quant-tf,
author={TensorFlow},
title={Post-training quantization},
url={https://www.tensorflow.org/lite/performance/post_training_quantization}
}

@misc{paszke2019pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{996017,
  author={Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II}, 
  year={2002},
  volume={6},
  number={2},
  pages={182-197},
  doi={10.1109/4235.996017}}


@Website{py-paretoarchive,
author={Vojtech Mrazek and Zdenek Vasicek},
title={Archive of non-dominated points},
url={https://github.com/ehw-fit/py-paretoarchive}
}

@Website{tf-model-optimization,
author={TensorFlow},
title={Model optimization},
url={https://www.tensorflow.org/model_optimization}
}

@PhdThesis{depthwise_conv,
author={Laurent Sifre and Stéphane Mallat},
title={Rigid-Motion Scattering For Image Classification},
school={CMAP, Ecole Polytechnique},
year={2014}
}

@INPROCEEDINGS{5206848,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@ARTICLE{9076333,
  author={Kwon, Hyoukjun and Chatarasi, Prasanth and Sarkar, Vivek and Krishna, Tushar and Pellauer, Michael and Parashar, Angshuman},
  journal={IEEE Micro}, 
  title={MAESTRO: A Data-Centric Approach to Understand Reuse, Performance, and Hardware Cost of DNN Mappings}, 
  year={2020},
  volume={40},
  number={3},
  pages={20-29},
  doi={10.1109/MM.2020.2985963}}

@INPROCEEDINGS{8695666,
  author={Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A. and Mukkara, Anurag and Venkatesan, Rangharajan and Khailany, Brucek and Keckler, Stephen W. and Emer, Joel},
  booktitle={2019 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Timeloop: A Systematic Approach to DNN Accelerator Evaluation}, 
  year={2019},
  volume={},
  number={},
  pages={304-315},
  doi={10.1109/ISPASS.2019.00042}}




