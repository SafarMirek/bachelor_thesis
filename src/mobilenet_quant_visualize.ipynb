{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_quantization.transforms.quantize_model import quantize_model\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:01:53.127448: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    }
   ],
   "source": [
    "# Load imagenet 100k dataset\n",
    "import imagenet_mini\n",
    "\n",
    "tr_ds = imagenet_mini.get_imagenet_mini_dataset(split=\"train\")\n",
    "tr_ds = tr_ds.map(imagenet_mini.get_preprocess_image_fn(image_size=(224, 224)))\n",
    "\n",
    "train_ds = tr_ds \\\n",
    "    .map(lambda data: (data['image'], data['label'])) \\\n",
    "    .batch(128)\n",
    "\n",
    "ds = imagenet_mini.get_imagenet_mini_dataset(split=\"val\")\n",
    "ds = ds.map(imagenet_mini.get_preprocess_image_fn(image_size=(224, 224)))\n",
    "\n",
    "test_ds = ds.map(lambda data: (data['image'], data['label'])).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:00:16.007261: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-27 13:00:16.007304: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNet(weights='imagenet', input_shape=(224, 224, 3), alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_0.25_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 8)       216       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 8)      32        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 8)       0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)      72        \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 8)      32        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 8)       0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 16)      128       \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 16)     64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 16)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)       144       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 16)       64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 16)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 32)        512       \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 32)        1024      \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 64)        4096      \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 128)        1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 128)        512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 256)         32768     \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 256)        2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 256)         65536     \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1, 1, 256)        0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        257000    \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 475,544\n",
      "Trainable params: 470,072\n",
      "Non-trainable params: 5,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantize model\n",
      "WARNING:tensorflow:From /Users/miroslavsafar/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"mobilenet_0.25_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " quantize_layer (QuantizeLay  (None, 224, 224, 3)      3         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " quant_conv1 (QuantizeWrappe  (None, 112, 112, 8)      233       \n",
      " rV2)                                                            \n",
      "                                                                 \n",
      " quant_conv1_bn (QuantizeWra  (None, 112, 112, 8)      33        \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_conv1_relu (QuantizeW  (None, 112, 112, 8)      3         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_1 (QuantizeWr  (None, 112, 112, 8)      75        \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_1_bn (Quantiz  (None, 112, 112, 8)      33        \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_1_relu (Quant  (None, 112, 112, 8)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_1 (QuantizeWr  (None, 112, 112, 16)     161       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_1_bn (Quantiz  (None, 112, 112, 16)     65        \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_1_relu (Quant  (None, 112, 112, 16)     3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_2 (QuantizeW  (None, 113, 113, 16)     1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_2 (QuantizeWr  (None, 56, 56, 16)       147       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_2_bn (Quantiz  (None, 56, 56, 16)       65        \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_2_relu (Quant  (None, 56, 56, 16)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_2 (QuantizeWr  (None, 56, 56, 32)       577       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_2_bn (Quantiz  (None, 56, 56, 32)       129       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_2_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_3 (QuantizeWr  (None, 56, 56, 32)       291       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_3_bn (Quantiz  (None, 56, 56, 32)       129       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_3_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_3 (QuantizeWr  (None, 56, 56, 32)       1089      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_3_bn (Quantiz  (None, 56, 56, 32)       129       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_3_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_4 (QuantizeW  (None, 57, 57, 32)       1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_4 (QuantizeWr  (None, 28, 28, 32)       291       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_4_bn (Quantiz  (None, 28, 28, 32)       129       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_4_relu (Quant  (None, 28, 28, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_4 (QuantizeWr  (None, 28, 28, 64)       2177      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_4_bn (Quantiz  (None, 28, 28, 64)       257       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_4_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_5 (QuantizeWr  (None, 28, 28, 64)       579       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_5_bn (Quantiz  (None, 28, 28, 64)       257       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_5_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_5 (QuantizeWr  (None, 28, 28, 64)       4225      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_5_bn (Quantiz  (None, 28, 28, 64)       257       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_5_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_6 (QuantizeW  (None, 29, 29, 64)       1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_6 (QuantizeWr  (None, 14, 14, 64)       579       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_6_bn (Quantiz  (None, 14, 14, 64)       257       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_6_relu (Quant  (None, 14, 14, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_6 (QuantizeWr  (None, 14, 14, 128)      8449      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_6_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_6_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_7 (QuantizeWr  (None, 14, 14, 128)      1155      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_7_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_7_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_7 (QuantizeWr  (None, 14, 14, 128)      16641     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_7_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_7_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_8 (QuantizeWr  (None, 14, 14, 128)      1155      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_8_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_8_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_8 (QuantizeWr  (None, 14, 14, 128)      16641     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_8_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_8_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_9 (QuantizeWr  (None, 14, 14, 128)      1155      \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_dw_9_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_9_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pw_9 (QuantizeWr  (None, 14, 14, 128)      16641     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv_pw_9_bn (Quantiz  (None, 14, 14, 128)      513       \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_conv_pw_9_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_dw_10 (QuantizeW  (None, 14, 14, 128)      1155      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_10_bn (Quanti  (None, 14, 14, 128)      513       \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_dw_10_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pw_10 (QuantizeW  (None, 14, 14, 128)      16641     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_pw_10_bn (Quanti  (None, 14, 14, 128)      513       \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_pw_10_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_dw_11 (QuantizeW  (None, 14, 14, 128)      1155      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_11_bn (Quanti  (None, 14, 14, 128)      513       \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_dw_11_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pw_11 (QuantizeW  (None, 14, 14, 128)      16641     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_pw_11_bn (Quanti  (None, 14, 14, 128)      513       \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_pw_11_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pad_12 (Quantize  (None, 15, 15, 128)      1         \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_12 (QuantizeW  (None, 7, 7, 128)        1155      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_12_bn (Quanti  (None, 7, 7, 128)        513       \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_dw_12_relu (Quan  (None, 7, 7, 128)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pw_12 (QuantizeW  (None, 7, 7, 256)        33281     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_pw_12_bn (Quanti  (None, 7, 7, 256)        1025      \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_pw_12_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_dw_13 (QuantizeW  (None, 7, 7, 256)        2307      \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_dw_13_bn (Quanti  (None, 7, 7, 256)        1025      \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_dw_13_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pw_13 (QuantizeW  (None, 7, 7, 256)        66049     \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv_pw_13_bn (Quanti  (None, 7, 7, 256)        1025      \n",
      " zeWrapperV2)                                                    \n",
      "                                                                 \n",
      " quant_conv_pw_13_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_global_average_poolin  (None, 1, 1, 256)        3         \n",
      " g2d (QuantizeWrapperV2)                                         \n",
      "                                                                 \n",
      " quant_dropout (QuantizeWrap  (None, 1, 1, 256)        1         \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_conv_preds (QuantizeW  (None, 1, 1, 1000)       259003    \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_reshape_2 (QuantizeWr  (None, 1000)             1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_predictions (Quantize  (None, 1000)             1         \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480,713\n",
      "Trainable params: 470,072\n",
      "Non-trainable params: 10,641\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantize model\")\n",
    "\n",
    "bit_8_conf = {\"weight_bits\": 8, \"activation_bits\": 8}\n",
    "bit_7_conf = {\"weight_bits\": 7, \"activation_bits\": 8}\n",
    "bit_6_conf = {\"weight_bits\": 6, \"activation_bits\": 8}\n",
    "bit_5_conf = {\"weight_bits\": 5, \"activation_bits\": 8}\n",
    "bit_4_conf = {\"weight_bits\": 4, \"activation_bits\": 8}\n",
    "bit_3_conf = {\"weight_bits\": 3, \"activation_bits\": 8}\n",
    "bit_2_conf = {\"weight_bits\": 2, \"activation_bits\": 8}\n",
    "\n",
    "q_aware_model = quantize_model(model, [\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf, bit_8_conf,\n",
    "    bit_8_conf, bit_8_conf\n",
    "])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.01),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:06:27.860953: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-27 13:06:30.107363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 4.3563 - accuracy: 0.1649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:14:00.954472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 462s 578ms/step - loss: 4.3563 - accuracy: 0.1649 - val_loss: 9.9378 - val_accuracy: 0.0115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dd3bf010>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train for one epoch\n",
    "q_aware_model.fit(train_ds, epochs=1, validation_data=test_ds, callbacks=[tensorboard_callback], initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 94723), started 0:08:01 ago. (Use '!kill 94723' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-39feca96c62bc9d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-39feca96c62bc9d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
