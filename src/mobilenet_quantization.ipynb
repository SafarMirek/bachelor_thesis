{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 15:48:13.850205: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 15:48:13.850225: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNet(weights='imagenet', input_shape=(224, 224, 3), alpha=0.25\n",
    "                                             )  #include_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mobilenet.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_0.25_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 8)       216       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 8)      32        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 8)       0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)      72        \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 8)      32        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 8)       0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 16)      128       \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 16)     64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 16)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)       144       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 16)       64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 16)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 32)        512       \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 32)        1024      \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 64)        4096      \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 128)        1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 128)        512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 256)         32768     \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 256)        2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 256)         65536     \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1, 1, 256)        0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        257000    \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 475,544\n",
      "Trainable params: 470,072\n",
      "Non-trainable params: 5,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representative dataset\n",
    "def representative_dataset(dataset):\n",
    "    def _data_gen():\n",
    "        for data in dataset.batch(1):\n",
    "            yield [data['image']]\n",
    "\n",
    "    return _data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tflite(tflite_model, dataset):\n",
    "    \"\"\"Evaluates tensorflow lite classification model with the given dataset.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_idx = interpreter.get_input_details()[0]['index']\n",
    "    output_idx = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for data in representative_dataset(dataset)():\n",
    "        interpreter.set_tensor(input_idx, data[0])\n",
    "        interpreter.invoke()\n",
    "        results.append(interpreter.get_tensor(output_idx).flatten())\n",
    "\n",
    "    results = np.array(results)\n",
    "    gt_labels = np.array(list(dataset.map(lambda data: data['label'])))\n",
    "    accuracy = (\n",
    "            np.sum(np.argsort(results, axis=1)[:, -1:] == gt_labels.reshape(-1, 1)) /\n",
    "            gt_labels.size)\n",
    "    print(f'Top-1 accuracy (quantized): {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/miroslavsafar/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/miroslavsafar/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "import imagenet_mini\n",
    "\n",
    "tr_ds = imagenet_mini.get_imagenet_mini_dataset(\"train\")\n",
    "tr_ds = tr_ds.map(imagenet_mini.get_preprocess_image_fn(image_size=(224, 224)))\n",
    "\n",
    "train_ds = tr_ds\\\n",
    "    .map(lambda data: (data['image'], data['label']))\\\n",
    "    .batch(256)\n",
    "\n",
    "ds = imagenet_mini.get_imagenet_mini_dataset(\"val\")\n",
    "ds = ds.map(imagenet_mini.get_preprocess_image_fn(image_size=(224, 224)))\n",
    "test_ds = ds.map(lambda data: (data['image'], data['label'])).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 15:48:14.839654: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-12 15:48:15.108252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 5s 108ms/step - loss: 3.1047 - accuracy: 0.3666\n",
      "Top-1 accuracy (float): 36.66%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f'Top-1 accuracy (float): {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers map:\n",
      "[{'conv_dw_5', 'conv_dw_5_relu', 'conv_dw_5_bn'}, {'conv_dw_13_relu', 'conv_dw_13_bn', 'conv_dw_13'}, {'conv_dw_11_bn', 'conv_dw_11_relu', 'conv_dw_11'}, {'conv_pw_13_bn', 'conv_pw_13', 'conv_pw_13_relu'}, {'conv_pad_2'}, {'conv_pw_5', 'conv_pw_5_relu', 'conv_pw_5_bn'}, {'conv_pw_12_relu', 'conv_pw_12', 'conv_pw_12_bn'}, {'conv_dw_10_bn', 'conv_dw_10_relu', 'conv_dw_10'}, {'conv_pw_6_bn', 'conv_pw_6_relu', 'conv_pw_6'}, {'conv_pw_7_relu', 'conv_pw_7', 'conv_pw_7_bn'}, {'conv_dw_2_relu', 'conv_dw_2_bn', 'conv_dw_2'}, {'conv_pw_1', 'conv_pw_1_relu', 'conv_pw_1_bn'}, {'conv_dw_7', 'conv_dw_7_bn', 'conv_dw_7_relu'}, {'conv_dw_3_relu', 'conv_dw_3', 'conv_dw_3_bn'}, {'conv1_relu', 'conv1', 'conv1_bn'}, {'conv_pw_9', 'conv_pw_9_relu', 'conv_pw_9_bn'}, {'conv_pw_8_bn', 'conv_pw_8', 'conv_pw_8_relu'}, {'conv_pw_3_bn', 'conv_pw_3', 'conv_pw_3_relu'}, {'conv_preds'}, {'predictions'}, {'dropout'}, {'global_average_pooling2d'}, {'conv_dw_12', 'conv_dw_12_bn', 'conv_dw_12_relu'}, {'conv_pw_2_bn', 'conv_pw_2', 'conv_pw_2_relu'}, {'conv_pw_4', 'conv_pw_4_bn', 'conv_pw_4_relu'}, {'conv_dw_9', 'conv_dw_9_relu', 'conv_dw_9_bn'}, {'conv_dw_1_bn', 'conv_dw_1', 'conv_dw_1_relu'}, {'conv_dw_8', 'conv_dw_8_bn', 'conv_dw_8_relu'}, {'conv_pw_10_relu', 'conv_pw_10_bn', 'conv_pw_10'}, {'conv_dw_4_relu', 'conv_dw_4_bn', 'conv_dw_4'}, {'conv_pad_6'}, {'conv_dw_6_relu', 'conv_dw_6_bn', 'conv_dw_6'}, {'conv_pad_4'}, {'input_1'}, {'reshape_2'}, {'conv_pw_11', 'conv_pw_11_relu', 'conv_pw_11_bn'}, {'conv_pad_12'}]\n",
      "Replacing DepthwiseConv2D (conv_dw_5) + BN (conv_dw_5_bn) -> QuantDepthwiseConv2DBN (conv_dw_5_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_13) + BN (conv_dw_13_bn) -> QuantDepthwiseConv2DBN (conv_dw_13_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_11) + BN (conv_dw_11_bn) -> QuantDepthwiseConv2DBN (conv_dw_11_bnfolded)\n",
      "Replacing Conv2D (conv_pw_13) + BN (conv_pw_13_bn) -> QuantConv2DBN (conv_pw_13_bnfolded)\n",
      "Replacing Conv2D (conv_pw_5) + BN (conv_pw_5_bn) -> QuantConv2DBN (conv_pw_5_bnfolded)\n",
      "Replacing Conv2D (conv_pw_12) + BN (conv_pw_12_bn) -> QuantConv2DBN (conv_pw_12_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_10) + BN (conv_dw_10_bn) -> QuantDepthwiseConv2DBN (conv_dw_10_bnfolded)\n",
      "Replacing Conv2D (conv_pw_6) + BN (conv_pw_6_bn) -> QuantConv2DBN (conv_pw_6_bnfolded)\n",
      "Replacing Conv2D (conv_pw_7) + BN (conv_pw_7_bn) -> QuantConv2DBN (conv_pw_7_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_2) + BN (conv_dw_2_bn) -> QuantDepthwiseConv2DBN (conv_dw_2_bnfolded)\n",
      "Replacing Conv2D (conv_pw_1) + BN (conv_pw_1_bn) -> QuantConv2DBN (conv_pw_1_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_7) + BN (conv_dw_7_bn) -> QuantDepthwiseConv2DBN (conv_dw_7_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_3) + BN (conv_dw_3_bn) -> QuantDepthwiseConv2DBN (conv_dw_3_bnfolded)\n",
      "Replacing Conv2D (conv1) + BN (conv1_bn) -> QuantConv2DBN (conv1_bnfolded)\n",
      "Replacing Conv2D (conv_pw_9) + BN (conv_pw_9_bn) -> QuantConv2DBN (conv_pw_9_bnfolded)\n",
      "Replacing Conv2D (conv_pw_8) + BN (conv_pw_8_bn) -> QuantConv2DBN (conv_pw_8_bnfolded)\n",
      "Replacing Conv2D (conv_pw_3) + BN (conv_pw_3_bn) -> QuantConv2DBN (conv_pw_3_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_12) + BN (conv_dw_12_bn) -> QuantDepthwiseConv2DBN (conv_dw_12_bnfolded)\n",
      "Replacing Conv2D (conv_pw_2) + BN (conv_pw_2_bn) -> QuantConv2DBN (conv_pw_2_bnfolded)\n",
      "Replacing Conv2D (conv_pw_4) + BN (conv_pw_4_bn) -> QuantConv2DBN (conv_pw_4_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_9) + BN (conv_dw_9_bn) -> QuantDepthwiseConv2DBN (conv_dw_9_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_1) + BN (conv_dw_1_bn) -> QuantDepthwiseConv2DBN (conv_dw_1_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_8) + BN (conv_dw_8_bn) -> QuantDepthwiseConv2DBN (conv_dw_8_bnfolded)\n",
      "Replacing Conv2D (conv_pw_10) + BN (conv_pw_10_bn) -> QuantConv2DBN (conv_pw_10_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_4) + BN (conv_dw_4_bn) -> QuantDepthwiseConv2DBN (conv_dw_4_bnfolded)\n",
      "Replacing DepthwiseConv2D (conv_dw_6) + BN (conv_dw_6_bn) -> QuantDepthwiseConv2DBN (conv_dw_6_bnfolded)\n",
      "Replacing Conv2D (conv_pw_11) + BN (conv_pw_11_bn) -> QuantConv2DBN (conv_pw_11_bnfolded)\n",
      "Model: \"mobilenet_0.25_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " quantize_layer_3 (QuantizeL  (None, 224, 224, 3)      3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " conv1_bnfolded (QuantConv2D  (None, 112, 112, 8)      264       \n",
      " BatchLayer)                                                     \n",
      "                                                                 \n",
      " quant_conv1_relu (QuantizeW  (None, 112, 112, 8)      3         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " conv_dw_1_bnfolded (QuantDe  (None, 112, 112, 8)      120       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_1_relu (Quant  (None, 112, 112, 8)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_1_bnfolded (QuantCo  (None, 112, 112, 16)     224       \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_1_relu (Quant  (None, 112, 112, 16)     3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_2 (QuantizeW  (None, 113, 113, 16)     1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " conv_dw_2_bnfolded (QuantDe  (None, 56, 56, 16)       240       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_2_relu (Quant  (None, 56, 56, 16)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_2_bnfolded (QuantCo  (None, 56, 56, 32)       704       \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_2_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_3_bnfolded (QuantDe  (None, 56, 56, 32)       480       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_3_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_3_bnfolded (QuantCo  (None, 56, 56, 32)       1216      \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_3_relu (Quant  (None, 56, 56, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_4 (QuantizeW  (None, 57, 57, 32)       1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " conv_dw_4_bnfolded (QuantDe  (None, 28, 28, 32)       480       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_4_relu (Quant  (None, 28, 28, 32)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_4_bnfolded (QuantCo  (None, 28, 28, 64)       2432      \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_4_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_5_bnfolded (QuantDe  (None, 28, 28, 64)       960       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_5_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_5_bnfolded (QuantCo  (None, 28, 28, 64)       4480      \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_5_relu (Quant  (None, 28, 28, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_conv_pad_6 (QuantizeW  (None, 29, 29, 64)       1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " conv_dw_6_bnfolded (QuantDe  (None, 14, 14, 64)       960       \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_6_relu (Quant  (None, 14, 14, 64)       3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_6_bnfolded (QuantCo  (None, 14, 14, 128)      8960      \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_6_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_7_bnfolded (QuantDe  (None, 14, 14, 128)      1920      \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_7_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_7_bnfolded (QuantCo  (None, 14, 14, 128)      17152     \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_7_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_8_bnfolded (QuantDe  (None, 14, 14, 128)      1920      \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_8_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_8_bnfolded (QuantCo  (None, 14, 14, 128)      17152     \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_8_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_9_bnfolded (QuantDe  (None, 14, 14, 128)      1920      \n",
      " pthwiseConv2DBatchNormaliza                                     \n",
      " tionLayer)                                                      \n",
      "                                                                 \n",
      " quant_conv_dw_9_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_pw_9_bnfolded (QuantCo  (None, 14, 14, 128)      17152     \n",
      " nv2DBatchLayer)                                                 \n",
      "                                                                 \n",
      " quant_conv_pw_9_relu (Quant  (None, 14, 14, 128)      3         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " conv_dw_10_bnfolded (QuantD  (None, 14, 14, 128)      1920      \n",
      " epthwiseConv2DBatchNormaliz                                     \n",
      " ationLayer)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_10_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_pw_10_bnfolded (QuantC  (None, 14, 14, 128)      17152     \n",
      " onv2DBatchLayer)                                                \n",
      "                                                                 \n",
      " quant_conv_pw_10_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_dw_11_bnfolded (QuantD  (None, 14, 14, 128)      1920      \n",
      " epthwiseConv2DBatchNormaliz                                     \n",
      " ationLayer)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_11_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_pw_11_bnfolded (QuantC  (None, 14, 14, 128)      17152     \n",
      " onv2DBatchLayer)                                                \n",
      "                                                                 \n",
      " quant_conv_pw_11_relu (Quan  (None, 14, 14, 128)      3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv_pad_12 (Quantize  (None, 15, 15, 128)      1         \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      " conv_dw_12_bnfolded (QuantD  (None, 7, 7, 128)        1920      \n",
      " epthwiseConv2DBatchNormaliz                                     \n",
      " ationLayer)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_12_relu (Quan  (None, 7, 7, 128)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_pw_12_bnfolded (QuantC  (None, 7, 7, 256)        34304     \n",
      " onv2DBatchLayer)                                                \n",
      "                                                                 \n",
      " quant_conv_pw_12_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_dw_13_bnfolded (QuantD  (None, 7, 7, 256)        3840      \n",
      " epthwiseConv2DBatchNormaliz                                     \n",
      " ationLayer)                                                     \n",
      "                                                                 \n",
      " quant_conv_dw_13_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " conv_pw_13_bnfolded (QuantC  (None, 7, 7, 256)        67072     \n",
      " onv2DBatchLayer)                                                \n",
      "                                                                 \n",
      " quant_conv_pw_13_relu (Quan  (None, 7, 7, 256)        3         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_global_average_poolin  (None, 1, 1, 256)        3         \n",
      " g2d (QuantizeWrapperV2)                                         \n",
      "                                                                 \n",
      " quant_dropout (QuantizeWrap  (None, 1, 1, 256)        1         \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_conv_preds (QuantizeW  (None, 1, 1, 1000)       259003    \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_reshape_2 (QuantizeWr  (None, 1000)             1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_predictions (Quantize  (None, 1000)             1         \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 483,113\n",
      "Trainable params: 470,072\n",
      "Non-trainable params: 13,041\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tf_quantization.quantize_model import quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "quant_layer_conf = {\"weight_bits\": 8, \"activation_bits\": 8}\n",
    "q_aware_model = quantize_model(model, [quant_layer_conf for i in range(36)] + [{\"weight_bits\": 8, \"activation_bits\": 8}])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer input_1: 0\n",
      "Layer quantize_layer_2: 0\n",
      "Layer conv1_bnfolded: 2240\n",
      "Layer quant_conv1_relu: 0\n",
      "Layer conv_dw_1_bnfolded: 1088\n",
      "Layer quant_conv_dw_1_relu: 0\n",
      "Layer conv_pw_1_bnfolded: 2048\n",
      "Layer quant_conv_pw_1_relu: 0\n",
      "Layer quant_conv_pad_2: 0\n",
      "Layer conv_dw_2_bnfolded: 2176\n",
      "Layer quant_conv_dw_2_relu: 0\n",
      "Layer conv_pw_2_bnfolded: 6144\n",
      "Layer quant_conv_pw_2_relu: 0\n",
      "Layer conv_dw_3_bnfolded: 4352\n",
      "Layer quant_conv_dw_3_relu: 0\n",
      "Layer conv_pw_3_bnfolded: 10240\n",
      "Layer quant_conv_pw_3_relu: 0\n",
      "Layer quant_conv_pad_4: 0\n",
      "Layer conv_dw_4_bnfolded: 4352\n",
      "Layer quant_conv_dw_4_relu: 0\n",
      "Layer conv_pw_4_bnfolded: 20480\n",
      "Layer quant_conv_pw_4_relu: 0\n",
      "Layer conv_dw_5_bnfolded: 8704\n",
      "Layer quant_conv_dw_5_relu: 0\n",
      "Layer conv_pw_5_bnfolded: 36864\n",
      "Layer quant_conv_pw_5_relu: 0\n",
      "Layer quant_conv_pad_6: 0\n",
      "Layer conv_dw_6_bnfolded: 8704\n",
      "Layer quant_conv_dw_6_relu: 0\n",
      "Layer conv_pw_6_bnfolded: 73728\n",
      "Layer quant_conv_pw_6_relu: 0\n",
      "Layer conv_dw_7_bnfolded: 17408\n",
      "Layer quant_conv_dw_7_relu: 0\n",
      "Layer conv_pw_7_bnfolded: 139264\n",
      "Layer quant_conv_pw_7_relu: 0\n",
      "Layer conv_dw_8_bnfolded: 17408\n",
      "Layer quant_conv_dw_8_relu: 0\n",
      "Layer conv_pw_8_bnfolded: 139264\n",
      "Layer quant_conv_pw_8_relu: 0\n",
      "Layer conv_dw_9_bnfolded: 17408\n",
      "Layer quant_conv_dw_9_relu: 0\n",
      "Layer conv_pw_9_bnfolded: 139264\n",
      "Layer quant_conv_pw_9_relu: 0\n",
      "Layer conv_dw_10_bnfolded: 17408\n",
      "Layer quant_conv_dw_10_relu: 0\n",
      "Layer conv_pw_10_bnfolded: 139264\n",
      "Layer quant_conv_pw_10_relu: 0\n",
      "Layer conv_dw_11_bnfolded: 17408\n",
      "Layer quant_conv_dw_11_relu: 0\n",
      "Layer conv_pw_11_bnfolded: 139264\n",
      "Layer quant_conv_pw_11_relu: 0\n",
      "Layer quant_conv_pad_12: 0\n",
      "Layer conv_dw_12_bnfolded: 17408\n",
      "Layer quant_conv_dw_12_relu: 0\n",
      "Layer conv_pw_12_bnfolded: 278528\n",
      "Layer quant_conv_pw_12_relu: 0\n",
      "Layer conv_dw_13_bnfolded: 34816\n",
      "Layer quant_conv_dw_13_relu: 0\n",
      "Layer conv_pw_13_bnfolded: 540672\n",
      "Layer quant_conv_pw_13_relu: 0\n",
      "Layer quant_global_average_pooling2d: 0\n",
      "Layer quant_dropout: 0\n",
      "Layer quant_conv_preds: 2112000\n",
      "Layer quant_reshape_2: 0\n",
      "Layer quant_predictions: 0\n",
      "Weights Size: 3.765 Mb\n"
     ]
    }
   ],
   "source": [
    "import calculate_model_size\n",
    "\n",
    "size = calculate_model_size.calculate_weights_mobilenet_size(q_aware_model)\n",
    "print(\"Weights Size: %.3f Mb\" % (size / 2**20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 15:24:29.464473: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mobilenet_1.00_224/quant_conv1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_1_relu/Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_2_relu/Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_2_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_4_relu/Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_4_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_6_relu/Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_6_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_12_relu/Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_12_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_preds/BiasAdd:0\", shape=(None, 1, 1, 1000), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_1_relu/Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_2_relu/Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_2_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_4_relu/Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_4_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_6_relu/Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_6_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_12_relu/Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_12_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_preds/BiasAdd:0\", shape=(None, 1, 1, 1000), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 15:24:33.180580: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/586 [>.............................] - ETA: 1:22:43 - loss: 6.5302 - accuracy: 0.0432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Compile model to disable weights learnings and allows model to learn activation quant ranges\u001B[39;00m\n\u001B[1;32m      2\u001B[0m q_aware_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mlegacy\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m),\n\u001B[1;32m      3\u001B[0m                       loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(),\n\u001B[1;32m      4\u001B[0m                       metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 6\u001B[0m \u001B[43mq_aware_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Compile model to disable weights learnings and allows model to learn activation quant ranges\n",
    "q_aware_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(train_ds.take(1), epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m qa_loss, qa_acc \u001B[38;5;241m=\u001B[39m \u001B[43mq_aware_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_ds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTop-1 accuracy (quantized, quant ranges updated): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mqa_acc\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/keras/engine/training.py:3690\u001B[0m, in \u001B[0;36mModel._assert_compile_was_called\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   3684\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_assert_compile_was_called\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   3685\u001B[0m     \u001B[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001B[39;00m\n\u001B[1;32m   3686\u001B[0m     \u001B[38;5;66;03m# then the optimizer is set. This is different from whether the\u001B[39;00m\n\u001B[1;32m   3687\u001B[0m     \u001B[38;5;66;03m# model is compiled\u001B[39;00m\n\u001B[1;32m   3688\u001B[0m     \u001B[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001B[39;00m\n\u001B[1;32m   3689\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_compiled:\n\u001B[0;32m-> 3690\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   3691\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must compile your model before \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3692\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining/testing. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3693\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `model.compile(optimizer, loss)`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3694\u001B[0m         )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "qa_loss, qa_acc = q_aware_model.evaluate(test_ds)\n",
    "print(f'Top-1 accuracy (quantized, quant ranges updated): {qa_acc * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "q_aware_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 378ms/step - loss: 2.2370 - accuracy: 0.5220\n",
      "Top-1 accuracy (quantize aware float): 52.20%\n"
     ]
    }
   ],
   "source": [
    "qa_loss, qa_acc = q_aware_model.evaluate(test_ds)\n",
    "print(f'Top-1 accuracy (quantize aware float): {qa_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "q_aware_model.save(\"q_aware_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mobilenet_1.00_224/quant_conv1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_1_relu/Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_2_relu/Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_2_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_4_relu/Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_4_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_6_relu/Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_6_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_12_relu/Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_12_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_dw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_conv_pw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"mobilenet_1.00_224/quant_global_average_pooling2d/Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"quant_conv1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_1_relu/Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_2_relu/Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_2_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_4_relu/Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_4_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_6_relu/Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_6_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_12_relu/Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_12_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_global_average_pooling2d/Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"quant_conv1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_1_relu/Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_1_relu/Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_2_relu/Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_2_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_3_relu/Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_4_relu/Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_4_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_5_relu/Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_6_relu/Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_6_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_7_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_8_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_9_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_10_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_11_relu/Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_12_relu/Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_12_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_conv_dw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_conv_pw_13_relu/Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"quant_global_average_pooling2d/Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 32), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 64), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 128), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Relu6:0\", shape=(None, 7, 7, 1024), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(None, 1, 1, 1024), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpm8y8uzbd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpm8y8uzbd/assets\n",
      "/Users/miroslavsafar/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-03-10 12:00:38.721800: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-10 12:00:38.721812: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-10 12:00:38.722134: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpm8y8uzbd\n",
      "2023-03-10 12:00:38.739570: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-10 12:00:38.739579: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpm8y8uzbd\n",
      "2023-03-10 12:00:38.793277: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-03-10 12:00:38.801799: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-10 12:00:39.097006: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpm8y8uzbd\n",
      "2023-03-10 12:00:39.168652: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 446517 microseconds.\n",
      "2023-03-10 12:00:39.384494: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 100\n",
      "Evaluated 200\n",
      "Evaluated 300\n",
      "Evaluated 400\n",
      "Evaluated 500\n",
      "Evaluated 600\n",
      "Evaluated 700\n",
      "Evaluated 800\n",
      "Evaluated 900\n",
      "Evaluated 1000\n",
      "Top-1 accuracy (quantized): 2.00%\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()\n",
    "eval_tflite(quantized_model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(quantized_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 28). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpdvttb3h2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpdvttb3h2/assets\n",
      "/Users/miroslavsafar/miniconda3/envs/bachelor_thesis/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-03-09 21:22:27.891470: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-09 21:22:27.891483: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-09 21:22:27.891568: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpdvttb3h2\n",
      "2023-03-09 21:22:27.898783: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-09 21:22:27.898794: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpdvttb3h2\n",
      "2023-03-09 21:22:27.922928: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-09 21:22:28.018585: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/zf/hqnjy5w17j5fsx1sf1rz_70r0000gn/T/tmpdvttb3h2\n",
      "2023-03-09 21:22:28.044367: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 152798 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset(tr_ds.take(1000))\n",
    "#converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "#converter2.inference_input_type = tf.int8  # or tf.uint8\n",
    "#converter2.inference_output_type = tf.int8  # or tf.uint8\n",
    "original_quantized_model = converter2.convert()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open('original_qmodel.tflite', 'wb') as f:\n",
    "  f.write(original_quantized_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 100\n",
      "Evaluated 200\n",
      "Evaluated 300\n",
      "Evaluated 400\n",
      "Evaluated 500\n",
      "Evaluated 600\n",
      "Evaluated 700\n",
      "Evaluated 800\n",
      "Evaluated 900\n",
      "Evaluated 1000\n",
      "Top-1 accuracy (quantized): 53.40%\n"
     ]
    }
   ],
   "source": [
    "eval_tflite(original_quantized_model, ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
